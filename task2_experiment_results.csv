Model,F1,F1 Appeal_to_Authority,F1 Appeal_to_fear-prejudice,"F1 Bandwagon,Reductio_ad_hitlerum",F1 Black-and-White_Fallacy,F1 Causal_Oversimplification,F1 Doubt,"F1 Exaggeration,Minimisation",F1 Flag-Waving,F1 Loaded_Language,"F1 Name_Calling,Labeling",F1 Repetition,F1 Slogans,F1 Thought-terminating_Cliches,"F1 Whataboutism,Straw_Men,Red_Herring",filename,
XLNET Large Cased + Linear,0.42145,0,0,0,0,0,0.09091,0.21569,0.2069,0.56768,0.64169,0.02804,0,0,0,xlnet_large_cased_task2.txt,
XLNET Base Cased + Linear,0.56632,0.10526,0.33333,0,0.07407,0.38095,0.46897,0.44086,0.69519,0.74586,0.70698,0.2654,0.29167,0.09091,0,xlnet_base_cased_task2.txt ,
Bert + Self Attention + Linear,0.54092,0,0.31579,0.5,0.12121,0.35714,0.48521,0.43787,0.70718,0.69293,0.60188,0.35391,0.40625,0.14815,0,task2_bert_sa_.txt ,
TFIDF SVM Classifier ,0.39229,0,0.18182,0.75,0.05556,0,0.31933,0.21849,0.56604,0.58422,0.38788,0.10762,0.0339,0.07018,0.10811,SVM_classifier_tfidf.txt,
Roberta Base + Linear,0.55691,0,0.31405,0,0,0.27586,0.45596,0.44262,0.67797,0.75294,0.63351,0.40927,0.27119,0,0,roberta_base_task2.txt,
Roberta Base + Self Attention + Linear,0.51552,0,0.31579,0.375,0.12121,0.18182,0.51282,0.33939,0.69565,0.68246,0.65491,0.22907,0.41667,0.12903,0.1, roberta_base_sa_t2.txt ,
Bert Large Uncased + Self Attention + Linear,0.57103,0.13333,0.31111,0,0.18182,0.29268,0.53595,0.45161,0.74854,0.75219,0.66499,0.28194,0.46875,0.2,0.1, bert__large_uncased_task2.txt ,
Bert Base Uncased + Linear,0.55503,0,0.28846,0,0,0.06667,0.52288,0.45455,0.71676,0.73228,0.67519,0.225,0.17778,0,0, bert_baseline_task2.txt,
Bert Base Uncased LM (Finetuned on Articles) + Self Attention + Linear,0.54563,0.125,0.33766,0.33333,0.15,0.27778,0.40678,0.39394,0.71523,0.69689,0.65217,0.32922,0.4,0.17143,0.25352,bb_sa_lm_preds_t2.txt ,
