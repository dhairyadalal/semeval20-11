{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "deeplearning",
   "display_name": "deeplearning"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_data = pd.read_csv(\"data/task2_data.csv\")\n",
    "train = all_data[all_data[\"source\"] == \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=\"ascii\",\n",
    "                        analyzer=\"word\",\n",
    "                        stop_words=\"english\",\n",
    "                        ngram_range=(1,3),\n",
    "                        min_df=2)\n",
    "tfidf = tfidf.fit(all_data[\"context\"])\n",
    "X_train = tfidf.transform(train[\"text\"])\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(train[\"label\"])\n",
    "y_train = le.transform(train[\"label\"])\n",
    "\n",
    "random_seed = 1956\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.15, random_state=random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = all_data[all_data[\"source\"]==\"dev\"][\"text\"]\n",
    "X_test = all_data[all_data[\"source\"]==\"test\"][\"text\"]\n",
    "\n",
    "X_dev = tfidf.transform(X_dev)\n",
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "clf1 = LinearSVC(C=1000)\n",
    "clf2 = AdaBoostClassifier()\n",
    "clf3 = RandomForestClassifier(n_jobs=-1, max_depth=8, n_estimators=500)\n",
    "lr = LogisticRegression()\n",
    "\n",
    "sclf = StackingCVClassifier(classifiers = [clf1, clf2, clf3],\n",
    "                            meta_classifier=lr,\n",
    "                            random_state=random_seed)\n",
    "params = {'adaboostclassifier__n_estimators': [50, 100, 150]}\n",
    "\n",
    "# grid = GridSearchCV(estimator=sclf, \n",
    "#                     param_grid=params, \n",
    "#                     cv=3,\n",
    "#                     refit=True)\n",
    "# grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "finished\n"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "from utils import generate_t2_sub\n",
    "import pickle\n",
    "\n",
    "ensembles =[\"stack_ensemble.pkl\",\n",
    "            \"stack_ensemble2.pkl\", \n",
    "            \"stack_ensemble3.pkl\", \n",
    "            \"stack_ensemble4.pkl\",\n",
    "            \"stack_ensemble5.pkl\",\n",
    "            \"stack_ensemble6.pkl\" ]\n",
    "\n",
    "dev = all_data[all_data[\"source\"]==\"dev\"]\n",
    "test = all_data[all_data[\"source\"]==\"test\"]\n",
    "\n",
    "X_dev = tfidf.transform(dev[\"text\"])\n",
    "X_test = tfidf.transform(test[\"text\"])\n",
    "\n",
    "for e in ensembles:\n",
    "    grid = pickle.load(open(e, \"rb\"))\n",
    "    clf = grid.best_estimator_\n",
    "    dev_pred = le.inverse_transform(clf.predict(X_dev))\n",
    "    test_pred = le.inverse_transform(clf.predict(X_test))\n",
    "    e_name = e.split(\".pkl\")[0]\n",
    "\n",
    "    idx = 0\n",
    "    with open(\"submissions/task2/dev_\" + e_name + \".txt\", \"w\") as f:\n",
    "        for i, r in dev.iterrows():\n",
    "            f.write(str(r.article_id)+ \"\\t\" + dev_pred[idx] + \"\\t\" + str(r.start) + \"\\t\" + str(r.end) + \"\\n\")\n",
    "            idx += 1\n",
    "\n",
    "    idx = 0\n",
    "    with open(\"submissions/task2/test_\" + e_name + \".txt\", \"w\") as f:\n",
    "        for i, r in test.iterrows():\n",
    "            f.write(str(r.article_id)+ \"\\t\" + test_pred[idx] + \"\\t\" +  str(r.start) + \"\\t\" + str(r.end) + \"\\n\")\n",
    "            idx += 1\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "all_data = pd.read_csv(\"data/task2_data.csv\")\n",
    "train = all_data[all_data[\"source\"] == \"train\"]\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\",\n",
    "                        min_df=2)\n",
    "\n",
    "tfidf = tfidf.fit(all_data[\"text\"])\n",
    "X_train = tfidf.transform(train[\"text\"])\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(train[\"label\"])\n",
    "y_train = le.transform(train[\"label\"])\n",
    "\n",
    "clf = SVC(C=1000, kernel=\"linear\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "dev = all_data[all_data[\"source\"]==\"dev\"]\n",
    "test = all_data[all_data[\"source\"]==\"test\"]\n",
    "\n",
    "X_dev = tfidf.transform(dev[\"text\"])\n",
    "\n",
    "dev_pred = clf.predict(X_dev)\n",
    "dev_preds = le.inverse_transform(dev_pred)\n",
    "\n",
    "with open(\"submissions/task2/dev_tfidf_svc.txt\", \"w\") as f:\n",
    "    idx=0\n",
    "    for i, r in dev.iterrows():\n",
    "        f.write(str(r.article_id)+ \"\\t\" + dev_preds[idx] + \"\\t\" + str(r.start) + \"\\t\" + str(r.end) + \"\\n\")\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1063"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}